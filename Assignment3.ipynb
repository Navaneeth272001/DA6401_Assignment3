{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89102e2a",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "In this assignment you will experiment with the [Dakshina dataset](https://github.com/google-research-datasets/dakshina) released by Google. This dataset contains pairs of the following form: \n",
    "\n",
    "$x$.      $y$\n",
    "\n",
    "ajanabee अजनबी.\n",
    "\n",
    "i.e., a word in the native script and its corresponding transliteration in the Latin script (the way we type while chatting with our friends on WhatsApp etc). Given many such $(x_i, y_i)_{i=1}^n$ pairs your goal is to train a model $y = \\hat{f}(x)$ which takes as input a romanized string (ghar) and produces the corresponding word in Devanagari (घर). \n",
    "\n",
    "As you would realise this is the problem of mapping a sequence of characters in one language to a sequence of characters in another language. Notice that this is a scaled down version of the problem of translation where the goal is to translate a sequence of **words** in one language to a sequence of words in another language (as opposed to sequence of **characters** here).\n",
    "\n",
    "Read these blogs to understand how to build neural sequence to sequence models: [blog1](https://keras.io/examples/nlp/lstm_seq2seq/), [blog2](https://machinelearningmastery.com/define-encoder-decoder-sequence-sequence-model-neural-machine-translation-keras/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "046b3fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "1. Roman: fiat                  →  Native: ஃபியட்\n",
      "2. Roman: phiyat                →  Native: ஃபியட்\n",
      "3. Roman: piyat                 →  Native: ஃபியட்\n",
      "4. Roman: firaans               →  Native: ஃபிரான்ஸ்\n",
      "5. Roman: france                →  Native: ஃபிரான்ஸ்\n",
      "Dev set\n",
      "1. Roman: fire                  →  Native: ஃபயர்\n",
      "2. Roman: phayar                →  Native: ஃபயர்\n",
      "3. Roman: baar                  →  Native: ஃபார்\n",
      "4. Roman: bar                   →  Native: ஃபார்\n",
      "5. Roman: far                   →  Native: ஃபார்\n"
     ]
    }
   ],
   "source": [
    "#This cell contains necessary code for dataset preprocessing and at the I print few examples for looking how the dataset looks like\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "trainPth = \"/mnt/e_disk/DA6401_Assignment3/dataset/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\"\n",
    "devPth   = \"/mnt/e_disk/DA6401_Assignment3/dataset/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.dev.tsv\"\n",
    "testPth = \"/mnt/e_disk/DA6401_Assignment3/dataset/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.test.tsv\"\n",
    "def get_vocab(paths):\n",
    "    chars = set()\n",
    "    for path in paths:\n",
    "        with open(path, encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                native, roman, _ = line.strip().split(\"\\t\")\n",
    "                chars.update(native)\n",
    "                chars.update(roman)\n",
    "    return chars\n",
    "\n",
    "def get_char2idx(char_set):\n",
    "    chars = [\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"] + sorted(char_set)\n",
    "    return {ch: i for i, ch in enumerate(chars)}, chars\n",
    "\n",
    "\n",
    "\n",
    "char_set = get_vocab([trainPth, devPth])\n",
    "roman2idx, idx2roman = get_char2idx(set(c for c in char_set if c.isascii()))\n",
    "dev2idx, idx2dev = get_char2idx(set(c for c in char_set if not c.isascii()))\n",
    "\n",
    "class TranslitDataset(Dataset):\n",
    "    def __init__(self, path, src_c2i, tgt_c2i, max_len=32):\n",
    "        self.data = []\n",
    "        with open(path, encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                native, roman, _ = line.strip().split(\"\\t\")\n",
    "                self.data.append((roman, native))\n",
    "        self.src_c2i = src_c2i\n",
    "        self.tgt_c2i = tgt_c2i\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        roman, native = self.data[i]\n",
    "        src = [self.src_c2i.get(c, self.src_c2i[\"<unk>\"]) for c in roman[:self.max_len]]\n",
    "        tgt = [self.tgt_c2i[\"<sos>\"]] + \\\n",
    "              [self.tgt_c2i.get(c, self.tgt_c2i[\"<unk>\"]) for c in native[:self.max_len - 1]] + \\\n",
    "              [self.tgt_c2i[\"<eos>\"]]\n",
    "        return torch.tensor(src), torch.tensor(tgt)\n",
    "\n",
    "def pad_batch(batch):\n",
    "    src, tgt = zip(*batch)\n",
    "    src = pad_sequence(src, batch_first=True, padding_value=roman2idx[\"<pad>\"])\n",
    "    tgt = pad_sequence(tgt, batch_first=True, padding_value=dev2idx[\"<pad>\"])\n",
    "    return src, tgt\n",
    "\n",
    "train_ds = TranslitDataset(trainPth, roman2idx, dev2idx, max_len=32)\n",
    "dev_ds   = TranslitDataset(devPth, roman2idx, dev2idx, max_len=32)\n",
    "test_ds   = TranslitDataset(testPth, roman2idx, dev2idx, max_len=32)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, collate_fn=pad_batch)\n",
    "dev_loader   = DataLoader(dev_ds, batch_size=32, shuffle=False, collate_fn=pad_batch)\n",
    "test_loader   = DataLoader(test_ds, batch_size=32, shuffle=False, collate_fn=pad_batch)\n",
    "\n",
    "\n",
    "print(\"Train set\")\n",
    "for i in range(5):\n",
    "    src, tgt = train_ds[i]\n",
    "    roman = ''.join([idx2roman[idx] for idx in src])\n",
    "    native = ''.join([idx2dev[idx] for idx in tgt[1:-1]])  # skip <sos> and <eos>\n",
    "    print(f\"{i+1}. Roman: {roman:20s}  →  Native: {native}\")\n",
    "print(\"Dev set\")\n",
    "for i in range(5):\n",
    "    src, tgt = dev_ds[i]\n",
    "    roman = ''.join([idx2roman[idx] for idx in src])\n",
    "    native = ''.join([idx2dev[idx] for idx in tgt[1:-1]])\n",
    "    print(f\"{i+1}. Roman: {roman:20s}  →  Native: {native}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5064eaa7",
   "metadata": {},
   "source": [
    "## Question 1 (15 Marks)\n",
    "Build a RNN based seq2seq model which contains the following layers: (i) input layer for character embeddings (ii) one encoder RNN which sequentially encodes the input character sequence (Latin) (iii) one decoder RNN which takes the last state of the encoder as input and produces one output character at a time (Devanagari). \n",
    "\n",
    "The code should be flexible such that the dimension of the input character embeddings, the hidden states of the encoders and decoders, the cell (RNN, LSTM, GRU) and the number of layers in the encoder and decoder can be changed.\n",
    "\n",
    "(a) What is the total number of computations done by your network? (assume that the input embedding size is $m$, encoder and decoder have 1 layer each, the hidden cell state is $k$ for both the encoder and decoder, the length of the input and output sequence is the same, i.e., $T$, the size of the vocabulary is the same for the source and target language, i.e., $V$)\n",
    "\n",
    "(b) What is the total number of parameters in your network? (assume that the input embedding size is $m$, encoder and decoder have 1 layer each, the hidden cell state is $k$ for both the encoder and decoder and the length of the input and output sequence is the same, i.e., $T$, the size of the vocabulary is the same for the source and target language, i.e., $V$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa928d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim, num_layers, cell_type='LSTM'):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        rnn_cls = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}[cell_type]\n",
    "        self.rnn = rnn_cls(emb_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.cell_type = cell_type\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.embedding(src)\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        return hidden  # hidden is tuple if LSTM, tensor otherwise\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hidden_dim, num_layers, cell_type='LSTM'):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        rnn_cls = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}[cell_type]\n",
    "        self.rnn = rnn_cls(emb_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.cell_type = cell_type\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # input: [batch_size]\n",
    "        input = input.unsqueeze(1)  # [batch_size, 1]\n",
    "        embedded = self.embedding(input)  # [batch_size, 1, emb_dim]\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        prediction = self.fc_out(output.squeeze(1))  # [batch_size, output_dim]\n",
    "        return prediction, hidden\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device, cell_type='LSTM'):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        self.cell_type = cell_type\n",
    "\n",
    "    def forward(self, src, tgt, teacher_forcing_ratio=0.5):\n",
    "        batch_size, tgt_len = tgt.shape\n",
    "        tgt_vocab_size = self.decoder.embedding.num_embeddings\n",
    "\n",
    "        outputs = torch.zeros(batch_size, tgt_len, tgt_vocab_size).to(self.device)\n",
    "\n",
    "        hidden = self.encoder(src)\n",
    "\n",
    "        # First input to decoder is <sos> token\n",
    "        input = tgt[:, 0]\n",
    "\n",
    "        for t in range(1, tgt_len):\n",
    "            output, hidden = self.decoder(input, hidden)\n",
    "            outputs[:, t] = output\n",
    "            top1 = output.argmax(1)\n",
    "            input = tgt[:, t] if torch.rand(1).item() < teacher_forcing_ratio else top1\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2912e05c",
   "metadata": {},
   "source": [
    "(a) What is the total number of computations done by your network? (assume that the input embedding size is $m$, encoder and decoder have 1 layer each, the hidden cell state is $k$ for both the encoder and decoder, the length of the input and output sequence is the same, i.e., $T$, the size of the vocabulary is the same for the source and target language, i.e., $V$)\n",
    "\n",
    "Given: \n",
    "- Input embedding size: m\n",
    "\n",
    "- Hidden size (encoder and decoder): k\n",
    "\n",
    "- Input and output sequence length: T\n",
    "\n",
    "- Vocabulary size (same for source and target): V\n",
    "\n",
    "- One encoder layer and one decoder layer\n",
    "\n",
    "- Model uses LSTM / GRU / RNN cells\n",
    "\n",
    "- Encoder:\n",
    "    - RNN: Cost per step=m⋅k+k⋅k=k(m+k)\n",
    "    - LSTM: Cost per step=4[k(m+k)]=4k(m+k) DUE TO 4 gates\n",
    "    - GRU: Cost per step=3k(m+k)\n",
    "    - Total cost for encoder = T⋅(cost per step)\n",
    "\n",
    "- Decoder:\n",
    "    - RNN: Cost per step=m⋅k+k⋅k=k(m+k)\n",
    "    - LSTM: Cost per step=4[k(m+k)]=4k(m+k) DUE TO 4 gates\n",
    "    - GRU: Cost per step=3k(m+k)\n",
    "    - Output projection cost per step: Hidden→Vocab:k⋅V\n",
    "    - Total cost for decoder = T⋅[RNN cost per step+k⋅V]\n",
    "\n",
    "Total cost = \n",
    "                - RNN = T⋅[2k(m+k)+kV]\n",
    "                - LSTM = T⋅[8k(m+k)+kV]\n",
    "                - GRU = T⋅[6k(m+k)+kV]\n",
    "\n",
    "(b) What is the total number of parameters in your network? (assume that the input embedding size is $m$, encoder and decoder have 1 layer each, the hidden cell state is $k$ for both the encoder and decoder and the length of the input and output sequence is the same, i.e., $T$, the size of the vocabulary is the same for the source and target language, i.e., $V$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aeeaa41",
   "metadata": {},
   "source": [
    "# Question 2 (10 Marks)\n",
    "\n",
    "You will now train your model using any one language from the [Dakshina dataset](https://github.com/google-research-datasets/dakshina) (I would suggest pick a language that you can read so that it is easy to analyse the errors). Use the standard train, dev, test set from the folder dakshina_dataset_v1.0/hi/lexicons/ (replace hi by the language of your choice)\n",
    "\n",
    "Using the sweep feature in wandb find the best hyperparameter configuration. Here are some suggestions but you are free to decide which hyperparameters you want to explore\n",
    "\n",
    "- input embedding size: 16, 32, 64, 256, ...\n",
    "- number of encoder layers: 1, 2, 3 \n",
    "- number of decoder layers: 1, 2, 3 \n",
    "- hidden layer size: 16, 32, 64, 256, ...\n",
    "- cell type: RNN, GRU, LSTM\n",
    "- dropout: 20%, 30% (btw, where will you add dropout? you should read up a bit on this)\n",
    "- beam search in decoder with different beam sizes: \n",
    "\n",
    "Based on your sweep please paste the following plots which are automatically generated by wandb:\n",
    "- accuracy v/s created plot (I would like to see the number of experiments you ran to get the best configuration). \n",
    "- parallel co-ordinates plot\n",
    "- correlation summary table (to see the correlation of each hyperparameter with the loss/accuracy)\n",
    "\n",
    "Also write down the hyperparameters and their values that you sweeped over. Smart strategies to reduce the number of runs while still achieving a high accuracy would be appreciated. Write down any unique strategy that you tried for efficiently searching the hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7799f3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 4gp89sqb\n",
      "Sweep URL: https://wandb.ai/navaneeth001/RNN-Seq2Seq/sweeps/4gp89sqb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5m89ii67 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseq_len: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvocab_size: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnavaneeth001\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/e_disk/DA6401_Assignment3/wandb/run-20250519_225051-5m89ii67</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq/runs/5m89ii67' target=\"_blank\">drawn-sweep-1</a></strong> to <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq/sweeps/4gp89sqb' target=\"_blank\">https://wandb.ai/navaneeth001/RNN-Seq2Seq/sweeps/4gp89sqb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq' target=\"_blank\">https://wandb.ai/navaneeth001/RNN-Seq2Seq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq/sweeps/4gp89sqb' target=\"_blank\">https://wandb.ai/navaneeth001/RNN-Seq2Seq/sweeps/4gp89sqb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq/runs/5m89ii67' target=\"_blank\">https://wandb.ai/navaneeth001/RNN-Seq2Seq/runs/5m89ii67</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▄▅▆▆▇▇▇▇█</td></tr><tr><td>train_loss</td><td>█▄▃▃▂▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▄▅▆█▁▇▅▆▇▅</td></tr><tr><td>val_loss</td><td>██▄▅█▃▄▁█▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_accuracy</td><td>0.37242</td></tr><tr><td>train_loss</td><td>2.14493</td></tr><tr><td>val_accuracy</td><td>0.19452</td></tr><tr><td>val_loss</td><td>2.75314</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cell_RNN/hid_256/emb_64/lay_2/lr_0.0001</strong> at: <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq/runs/5m89ii67' target=\"_blank\">https://wandb.ai/navaneeth001/RNN-Seq2Seq/runs/5m89ii67</a><br> View project at: <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq' target=\"_blank\">https://wandb.ai/navaneeth001/RNN-Seq2Seq</a><br>Synced 5 W&B file(s), 0 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250519_225051-5m89ii67/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mxx5i166 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseq_len: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvocab_size: 50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/e_disk/DA6401_Assignment3/wandb/run-20250519_225808-mxx5i166</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq/runs/mxx5i166' target=\"_blank\">peachy-sweep-2</a></strong> to <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq/sweeps/4gp89sqb' target=\"_blank\">https://wandb.ai/navaneeth001/RNN-Seq2Seq/sweeps/4gp89sqb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq' target=\"_blank\">https://wandb.ai/navaneeth001/RNN-Seq2Seq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq/sweeps/4gp89sqb' target=\"_blank\">https://wandb.ai/navaneeth001/RNN-Seq2Seq/sweeps/4gp89sqb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq/runs/mxx5i166' target=\"_blank\">https://wandb.ai/navaneeth001/RNN-Seq2Seq/runs/mxx5i166</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▆▇▇▇█████</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▇▇▇█████</td></tr><tr><td>val_loss</td><td>█▃▂▂▁▁▁▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_accuracy</td><td>0.92036</td></tr><tr><td>train_loss</td><td>0.3229</td></tr><tr><td>val_accuracy</td><td>0.76671</td></tr><tr><td>val_loss</td><td>1.06094</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cell_LSTM/hid_128/emb_128/lay_1/lr_0.001</strong> at: <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq/runs/mxx5i166' target=\"_blank\">https://wandb.ai/navaneeth001/RNN-Seq2Seq/runs/mxx5i166</a><br> View project at: <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq' target=\"_blank\">https://wandb.ai/navaneeth001/RNN-Seq2Seq</a><br>Synced 5 W&B file(s), 0 media file(s), 12 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250519_225808-mxx5i166/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4ukfqgll with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseq_len: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvocab_size: 50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/e_disk/DA6401_Assignment3/wandb/run-20250519_230531-4ukfqgll</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq/runs/4ukfqgll' target=\"_blank\">electric-sweep-3</a></strong> to <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq/sweeps/4gp89sqb' target=\"_blank\">https://wandb.ai/navaneeth001/RNN-Seq2Seq/sweeps/4gp89sqb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq' target=\"_blank\">https://wandb.ai/navaneeth001/RNN-Seq2Seq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq/sweeps/4gp89sqb' target=\"_blank\">https://wandb.ai/navaneeth001/RNN-Seq2Seq/sweeps/4gp89sqb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq/runs/4ukfqgll' target=\"_blank\">https://wandb.ai/navaneeth001/RNN-Seq2Seq/runs/4ukfqgll</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▅▆▆▇▇▇███</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▆▇▅▇▇▇▇█▇</td></tr><tr><td>val_loss</td><td>█▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_accuracy</td><td>0.35768</td></tr><tr><td>train_loss</td><td>2.19766</td></tr><tr><td>val_accuracy</td><td>0.19758</td></tr><tr><td>val_loss</td><td>2.73217</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cell_RNN/hid_256/emb_64/lay_1/lr_0.0001</strong> at: <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq/runs/4ukfqgll' target=\"_blank\">https://wandb.ai/navaneeth001/RNN-Seq2Seq/runs/4ukfqgll</a><br> View project at: <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq' target=\"_blank\">https://wandb.ai/navaneeth001/RNN-Seq2Seq</a><br>Synced 5 W&B file(s), 0 media file(s), 12 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250519_230531-4ukfqgll/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: as7lo7r2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseq_len: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvocab_size: 50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/e_disk/DA6401_Assignment3/wandb/run-20250519_231146-as7lo7r2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq/runs/as7lo7r2' target=\"_blank\">flowing-sweep-4</a></strong> to <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq/sweeps/4gp89sqb' target=\"_blank\">https://wandb.ai/navaneeth001/RNN-Seq2Seq/sweeps/4gp89sqb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq' target=\"_blank\">https://wandb.ai/navaneeth001/RNN-Seq2Seq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq/sweeps/4gp89sqb' target=\"_blank\">https://wandb.ai/navaneeth001/RNN-Seq2Seq/sweeps/4gp89sqb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq/runs/as7lo7r2' target=\"_blank\">https://wandb.ai/navaneeth001/RNN-Seq2Seq/runs/as7lo7r2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_accuracy</td><td>▁▃▄▅▅▆▇▇▇▇█████</td></tr><tr><td>train_loss</td><td>█▆▅▄▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▂▃▄▅▅▆▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█▇▆▅▄▃▃▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>train_accuracy</td><td>0.85372</td></tr><tr><td>train_loss</td><td>0.56528</td></tr><tr><td>val_accuracy</td><td>0.72734</td></tr><tr><td>val_loss</td><td>1.08085</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cell_LSTM/hid_128/emb_128/lay_1/lr_0.0001</strong> at: <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq/runs/as7lo7r2' target=\"_blank\">https://wandb.ai/navaneeth001/RNN-Seq2Seq/runs/as7lo7r2</a><br> View project at: <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq' target=\"_blank\">https://wandb.ai/navaneeth001/RNN-Seq2Seq</a><br>Synced 5 W&B file(s), 0 media file(s), 30 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250519_231146-as7lo7r2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f2jrev21 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseq_len: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tvocab_size: 50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/e_disk/DA6401_Assignment3/wandb/run-20250519_232310-f2jrev21</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq/runs/f2jrev21' target=\"_blank\">solar-sweep-5</a></strong> to <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq/sweeps/4gp89sqb' target=\"_blank\">https://wandb.ai/navaneeth001/RNN-Seq2Seq/sweeps/4gp89sqb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq' target=\"_blank\">https://wandb.ai/navaneeth001/RNN-Seq2Seq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq/sweeps/4gp89sqb' target=\"_blank\">https://wandb.ai/navaneeth001/RNN-Seq2Seq/sweeps/4gp89sqb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq/runs/f2jrev21' target=\"_blank\">https://wandb.ai/navaneeth001/RNN-Seq2Seq/runs/f2jrev21</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_accuracy</td><td>▁▅▆▇▇▇▇████████</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅▇▇▇▇███████▇</td></tr><tr><td>val_loss</td><td>█▄▄▂▂▂▂▂▁▂▂▂▂▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>train_accuracy</td><td>0.93539</td></tr><tr><td>train_loss</td><td>0.26357</td></tr><tr><td>val_accuracy</td><td>0.76376</td></tr><tr><td>val_loss</td><td>1.13907</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cell_LSTM/hid_128/emb_128/lay_1/lr_0.001</strong> at: <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq/runs/f2jrev21' target=\"_blank\">https://wandb.ai/navaneeth001/RNN-Seq2Seq/runs/f2jrev21</a><br> View project at: <a href='https://wandb.ai/navaneeth001/RNN-Seq2Seq' target=\"_blank\">https://wandb.ai/navaneeth001/RNN-Seq2Seq</a><br>Synced 5 W&B file(s), 0 media file(s), 14 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250519_232310-f2jrev21/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as opt\n",
    "import wandb\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define Encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim, num_layers, cell_type):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = getattr(nn, cell_type.upper())(emb_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        embedded = self.embedding(src)\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        return hidden\n",
    "\n",
    "# Define Decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hidden_dim, num_layers, cell_type):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = getattr(nn, cell_type.upper())(emb_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input.unsqueeze(1))\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        prediction = self.fc_out(output.squeeze(1))\n",
    "        return prediction, hidden\n",
    "\n",
    "# Define Seq2Seq\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "    \n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size, trg_len = trg.shape\n",
    "        output_dim = self.decoder.fc_out.out_features\n",
    "        outputs = torch.zeros(batch_size, trg_len, output_dim).to(self.device)\n",
    "        hidden = self.encoder(src)\n",
    "        input = trg[:, 0]  # <sos> token\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden = self.decoder(input, hidden)\n",
    "            outputs[:, t] = output\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            input = trg[:, t] if teacher_force else output.argmax(1)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "# Model Trainer\n",
    "def train_model(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "        wandb.run.name = f\"cell_{config.cell_type}/hid_{config.hidden_dim}/emb_{config.emb_dim}/lay_{config.num_layers}/lr_{config.lr}\"\n",
    "\n",
    "        device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "        # Vocab and dataset setup\n",
    "        vocab_size = config.vocab_size\n",
    "        input_dim = output_dim = vocab_size\n",
    "\n",
    "        encoder = Encoder(input_dim, config.emb_dim, config.hidden_dim, config.num_layers, config.cell_type)\n",
    "        decoder = Decoder(output_dim, config.emb_dim, config.hidden_dim, config.num_layers, config.cell_type)\n",
    "        model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "        optimizer = opt.Adam(model.parameters(), lr=config.lr)\n",
    "        criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        best_epoch = 0\n",
    "        save_path = os.path.join(wandb.run.dir, 'best_model.pth')\n",
    "\n",
    "        for epoch in range(config.epochs):\n",
    "            model.train()\n",
    "            epoch_loss, epoch_correct, total = 0, 0, 0\n",
    "            for src, trg in train_loader:\n",
    "                src, trg = src.to(device), trg.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(src, trg)  # output: [batch, trg_len, vocab_size]\n",
    "                output = output[:, 1:].reshape(-1, vocab_size)\n",
    "                trg_reshaped = trg[:, 1:].reshape(-1)\n",
    "\n",
    "                loss = criterion(output, trg_reshaped)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item() * src.size(0)\n",
    "\n",
    "                # Accuracy\n",
    "                preds = output.argmax(1)\n",
    "                mask = trg_reshaped != 0\n",
    "                epoch_correct += ((preds == trg_reshaped) & mask).sum().item()\n",
    "                total += mask.sum().item()\n",
    "\n",
    "            train_loss = epoch_loss / len(train_ds)\n",
    "            train_acc = epoch_correct / total if total > 0 else 0\n",
    "\n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_correct, val_total = 0, 0\n",
    "            with torch.no_grad():\n",
    "                for src, trg in dev_loader:\n",
    "                    src, trg = src.to(device), trg.to(device)\n",
    "                    output = model(src, trg, teacher_forcing_ratio=0.0)\n",
    "                    output = output[:, 1:].reshape(-1, vocab_size)\n",
    "                    trg_reshaped = trg[:, 1:].reshape(-1)\n",
    "\n",
    "                    loss = criterion(output, trg_reshaped)\n",
    "                    val_loss += loss.item() * src.size(0)\n",
    "\n",
    "                    preds = output.argmax(1)\n",
    "                    mask = trg_reshaped != 0\n",
    "                    val_correct += ((preds == trg_reshaped) & mask).sum().item()\n",
    "                    val_total += mask.sum().item()\n",
    "\n",
    "            val_loss /= len(dev_ds)\n",
    "            val_acc = val_correct / val_total if val_total > 0 else 0\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), save_path)\n",
    "                artifact = wandb.Artifact('best-model', type='model')\n",
    "                artifact.add_file(save_path)\n",
    "                wandb.log_artifact(artifact)\n",
    "\n",
    "            wandb.log({\n",
    "                'epoch': epoch + 1,\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_loss,\n",
    "                'train_accuracy': train_acc,\n",
    "                'val_accuracy': val_acc\n",
    "            })\n",
    "\n",
    "\n",
    "# Sweep config\n",
    "sweep_config = {\n",
    "    'method': 'bayes',\n",
    "    'metric': {'name': 'val_loss', 'goal': 'minimize'},\n",
    "    'parameters': {\n",
    "        'epochs': {'values': [10, 15]},\n",
    "        'vocab_size': {'value': 50},\n",
    "        'seq_len': {'value': 20},\n",
    "        'emb_dim': {'values': [64, 128]},\n",
    "        'hidden_dim': {'values': [128, 256]},\n",
    "        'num_layers': {'values': [1, 2]},\n",
    "        'cell_type': {'values': ['RNN', 'GRU', 'LSTM']},\n",
    "        'lr': {'values': [1e-3, 1e-4]},\n",
    "        'batch_size': {'values': [32, 64]}\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project='RNN-Seq2Seq')\n",
    "wandb.agent(sweep_id, function=train_model, count=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a59b3e",
   "metadata": {},
   "source": [
    "# Question 3 (15 Marks)\n",
    "Based on the above plots write down some insightful observations. For example, \n",
    "- RNN based model takes longer time to converge than GRU or LSTM\n",
    "- using smaller sizes for the hidden layer does not give good results\n",
    "- dropout leads to better performance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05bfd19",
   "metadata": {},
   "source": [
    "# Question 4 (10 Marks)\n",
    "\n",
    "You will now apply your best model on the test data (You shouldn't have used test data so far. All the above experiments should have been done using train and val data only). \n",
    "\n",
    "(a) Use the best model from your sweep and report the accuracy on the test set (the output is correct only if it exactly matches the reference output). \n",
    "\n",
    "(b) Provide sample inputs from the test data and predictions made by your best model (more marks for presenting this grid creatively). Also upload all the predictions on the test set in a folder **predictions_vanilla** on your github project.\n",
    "\n",
    "(c) Comment on the errors made by your model (simple insightful bullet points)\n",
    "\n",
    "- The model makes more errors on consonants than vowels\n",
    "- The model makes more errors on longer sequences\n",
    "- I am thinking confusion matrix but may be it's just me!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bafd665f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'RNN-Seq2Seq' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Ignoring entity 'navaneeth001' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model artifact to: /mnt/e_disk/DA6401_Assignment3/artifacts/best-model:v40/best_model.pth\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Seq2Seq.__init__() got an unexpected keyword argument 'input_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_ds, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mpad_batch)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Define your Seq2Seq model\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSeq2Seq\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mroman2idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdev2idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43memb_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memb_dim\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43menc_hidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43menc_hidden_dim\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdec_hidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdec_hidden_dim\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43menc_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43menc_layers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdec_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdec_layers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdropout\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Load model state\u001b[39;00m\n\u001b[1;32m     54\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Seq2Seq.__init__() got an unexpected keyword argument 'input_dim'"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb import Api\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load best run from sweep\n",
    "ENTITY      = 'navaneeth001'\n",
    "PROJECT     = 'RNN-Seq2Seq'\n",
    "SWEEP_ID    = '4gp89sqb'\n",
    "ARTIFACT_REF= 'navaneeth001/RNN-Seq2Seq/best-model:v40'\n",
    "\n",
    "api         = Api()\n",
    "sweep       = api.sweep(f\"{ENTITY}/{PROJECT}/{SWEEP_ID}\")\n",
    "runs        = sweep.runs\n",
    "best_run    = max(runs, key=lambda r: r.summary.get('val_acc', 0))\n",
    "cfg         = best_run.config\n",
    "\n",
    "# Start evaluation run\n",
    "eval_run = wandb.init(\n",
    "    project=PROJECT,\n",
    "    entity=ENTITY,\n",
    "    job_type='evaluation'\n",
    ")\n",
    "\n",
    "# Load artifact\n",
    "artifact       = eval_run.use_artifact(ARTIFACT_REF, type='model')\n",
    "download_dir   = artifact.download()\n",
    "model_path     = os.path.join(download_dir, 'best_model.pth')\n",
    "print(f\"Loaded model artifact to: {model_path}\")\n",
    "\n",
    "# # Load vocab (replace with your actual vocab load)\n",
    "# roman2idx, idx2roman = ...  # dicts\n",
    "# dev2idx, idx2dev     = ...\n",
    "\n",
    "# Dataset and DataLoader\n",
    "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False, collate_fn=pad_batch)\n",
    "\n",
    "# Define your Seq2Seq model\n",
    "model = Seq2Seq(\n",
    "    input_dim=len(roman2idx),\n",
    "    output_dim=len(dev2idx),\n",
    "    emb_dim=cfg.get('emb_dim', 256),\n",
    "    enc_hidden_dim=cfg.get('enc_hidden_dim', 512),\n",
    "    dec_hidden_dim=cfg.get('dec_hidden_dim', 512),\n",
    "    enc_layers=cfg.get('enc_layers', 1),\n",
    "    dec_layers=cfg.get('dec_layers', 1),\n",
    "    dropout=cfg.get('dropout', 0.1)\n",
    ")\n",
    "\n",
    "# Load model state\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "state  = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "model.to(device).eval()\n",
    "\n",
    "# Prediction function\n",
    "def predict(model, src, sos_idx, eos_idx, max_len=32):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        results = []\n",
    "        for s in src:\n",
    "            s = s.unsqueeze(0).to(device)\n",
    "            tgt_seq = [sos_idx]\n",
    "            for _ in range(max_len):\n",
    "                tgt_tensor = torch.tensor(tgt_seq).unsqueeze(0).to(device)\n",
    "                out = model(s, tgt_tensor, teacher_forcing_ratio=0.0)\n",
    "                next_token = out[0, -1].argmax().item()\n",
    "                if next_token == eos_idx:\n",
    "                    break\n",
    "                tgt_seq.append(next_token)\n",
    "            results.append(tgt_seq[1:])\n",
    "        return results\n",
    "\n",
    "# Evaluate and collect samples\n",
    "all_romans, all_preds, all_refs = [], [], []\n",
    "correct, total = 0, 0\n",
    "\n",
    "for src_batch, tgt_batch in test_loader:\n",
    "    src_batch = src_batch.to(device)\n",
    "    tgt_batch = tgt_batch.to(device)\n",
    "    preds = predict(model, src_batch, dev2idx[\"<sos>\"], dev2idx[\"<eos>\"])\n",
    "\n",
    "    for src, pred, tgt in zip(src_batch, preds, tgt_batch):\n",
    "        roman = ''.join([idx2roman[idx.item()] for idx in src if idx2roman[idx.item()] != \"<pad>\"])\n",
    "        pred_str = ''.join([idx2dev[idx] for idx in pred])\n",
    "        ref_str = ''.join([\n",
    "            idx2dev[idx.item()]\n",
    "            for idx in tgt[1:]\n",
    "            if idx.item() not in (dev2idx[\"<pad>\"], dev2idx[\"<eos>\"])\n",
    "        ])\n",
    "\n",
    "        all_romans.append(roman)\n",
    "        all_preds.append(pred_str)\n",
    "        all_refs.append(ref_str)\n",
    "\n",
    "        # Simple accuracy comparison\n",
    "        if pred_str == ref_str:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "\n",
    "# Final test accuracy\n",
    "test_acc = 100.0 * correct / total\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "# Visualization\n",
    "df = pd.DataFrame({\n",
    "    \"Roman Input\": all_romans[:10],\n",
    "    \"Predicted Tamil\": all_preds[:10],\n",
    "    \"Ground Truth\": all_refs[:10]\n",
    "})\n",
    "print(df)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 2))\n",
    "ax.axis('off')\n",
    "table = ax.table(cellText=df.values, colLabels=df.columns, cellLoc='center', loc='center')\n",
    "table.scale(1, 2)\n",
    "plt.title(\"Sample Transliteration Predictions\")\n",
    "plt.show()\n",
    "\n",
    "eval_run.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc9aa20",
   "metadata": {},
   "source": [
    "# Question 5 (20 Marks)\n",
    "\n",
    "Now add an attention network to your basis sequence to sequence model and train the model again. For the sake of simplicity you can use a single layered encoder and a single layered decoder (if you want you can use multiple layers also). Please answer the following questions:\n",
    "\n",
    "(a) Did you tune the hyperparameters again? If yes please paste appropriate plots below.\n",
    "\n",
    "(b) Evaluate your best model on the test set and report the accuracy. Also upload all the predictions on the test set in a folder **predictions_attention** on your github project.\n",
    "\n",
    "(c) Does the attention based model perform better than the vanilla model? If so, can you check some of the errors that this model corrected and note down your inferences (i.e., outputs which were predicted incorrectly by your best seq2seq model are predicted correctly by this model)\n",
    "\n",
    "(d) In a 3 x 3 grid paste the attention heatmaps for 10 inputs from your test data (read up on what are attention heatmaps).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6849d04a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5b4e5a2",
   "metadata": {},
   "source": [
    "# Question 6 (20 Marks)\n",
    "\n",
    "This a challenge question and most of you will find it hard. \n",
    "\n",
    "I like the visualisation in the figure captioned \"Connectivity\" in this [article](https://distill.pub/2019/memorization-in-rnns/#appendix-autocomplete). Make a similar visualisation for your model. Please look at this [blog](https://medium.com/data-science/visualising-lstm-activations-in-keras-b50206da96ff) for some starter code. The goal is to figure out the following: When the model is decoding the $i$-th character in the output which is the input character that it is looking at?\n",
    "\n",
    "Have fun!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "da24s008",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
